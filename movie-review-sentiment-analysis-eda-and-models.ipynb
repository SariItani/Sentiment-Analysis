{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"839fc1317e1b7253241839bbfa2d40303c53a3f1"},"source":["## General information\n","\n","In this kernel I'll work with data from Movie Review Sentiment Analysis Playground Competition.\n","\n","This dataset is interesting for NLP researching. Sentences from original dataset were split in separate phrases and each of them has a sentiment label. Also a lot of phrases are really short which makes classifying them quite challenging. Let's try!"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-31T12:13:17.982152Z","iopub.status.busy":"2024-03-31T12:13:17.981696Z","iopub.status.idle":"2024-03-31T12:13:17.992964Z","shell.execute_reply":"2024-03-31T12:13:17.992342Z","shell.execute_reply.started":"2024-03-31T12:13:17.982074Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","from nltk.tokenize import TweetTokenizer\n","import datetime\n","import lightgbm as lgb\n","from scipy import stats\n","from scipy.sparse import hstack, csr_matrix\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from wordcloud import WordCloud\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from nltk.util import ngrams\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.multiclass import OneVsRestClassifier\n","pd.set_option('max_colwidth',400)"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2024-03-31T12:13:17.994600Z","iopub.status.busy":"2024-03-31T12:13:17.994250Z","iopub.status.idle":"2024-03-31T12:13:18.337753Z","shell.execute_reply":"2024-03-31T12:13:18.337128Z","shell.execute_reply.started":"2024-03-31T12:13:17.994544Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["import zipfile\n","\n","# Specify the path to the zip file\n","zip_path = 'train.tsv.zip'\n","\n","# Open the zip file\n","with zipfile.ZipFile(zip_path, 'r') as zip_file:\n","    # Extract the TSV file from the zip\n","    tsv_filename = zip_file.namelist()[0]  # Assumes the TSV file is the first file in the zip\n","    with zip_file.open(tsv_filename) as tsv_file:\n","        # Read the TSV file using pandas\n","        train = pd.read_csv(tsv_file, delimiter='\\t')\n","\n","# Repeat the same process for the test data\n","test_zip_path = 'test.tsv.zip'\n","with zipfile.ZipFile(test_zip_path, 'r') as test_zip_file:\n","    test_tsv_filename = test_zip_file.namelist()[0]\n","    with test_zip_file.open(test_tsv_filename) as test_tsv_file:\n","        test = pd.read_csv(test_tsv_file, delimiter='\\t')\n","sub = pd.read_csv('sampleSubmission.csv', sep=',')"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"f9b8d8423bb09068cb168b67f4756ee8b250fc8c","execution":{"iopub.execute_input":"2024-03-31T12:13:18.339302Z","iopub.status.busy":"2024-03-31T12:13:18.339087Z","iopub.status.idle":"2024-03-31T12:13:18.367162Z","shell.execute_reply":"2024-03-31T12:13:18.366529Z","shell.execute_reply.started":"2024-03-31T12:13:18.339265Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PhraseId</th>\n","      <th>SentenceId</th>\n","      <th>Phrase</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>A series</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>series</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>of escapades demonstrating the adage that what is good for the goose</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>of</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>escapades demonstrating the adage that what is good for the goose</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>escapades</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>demonstrating the adage that what is good for the goose</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PhraseId    ...      Sentiment\n","0         1    ...              1\n","1         2    ...              2\n","2         3    ...              2\n","3         4    ...              2\n","4         5    ...              2\n","5         6    ...              2\n","6         7    ...              2\n","7         8    ...              2\n","8         9    ...              2\n","9        10    ...              2\n","\n","[10 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train.head(10)"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"e94f8371d8be87186f23ecc75178480d3d96bd78","execution":{"iopub.execute_input":"2024-03-31T12:13:18.368541Z","iopub.status.busy":"2024-03-31T12:13:18.368334Z","iopub.status.idle":"2024-03-31T12:13:18.388505Z","shell.execute_reply":"2024-03-31T12:13:18.387880Z","shell.execute_reply.started":"2024-03-31T12:13:18.368504Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PhraseId</th>\n","      <th>SentenceId</th>\n","      <th>Phrase</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>63</th>\n","      <td>64</td>\n","      <td>2</td>\n","      <td>This quiet , introspective and entertaining independent is worth seeking .</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>65</td>\n","      <td>2</td>\n","      <td>This quiet , introspective and entertaining independent</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>66</td>\n","      <td>2</td>\n","      <td>This</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>67</td>\n","      <td>2</td>\n","      <td>quiet , introspective and entertaining independent</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>68</td>\n","      <td>2</td>\n","      <td>quiet , introspective and entertaining</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>69</td>\n","      <td>2</td>\n","      <td>quiet</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>70</td>\n","      <td>2</td>\n","      <td>, introspective and entertaining</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>71</td>\n","      <td>2</td>\n","      <td>introspective and entertaining</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>72</td>\n","      <td>2</td>\n","      <td>introspective and</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>73</td>\n","      <td>2</td>\n","      <td>introspective</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>74</td>\n","      <td>2</td>\n","      <td>and</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>75</td>\n","      <td>2</td>\n","      <td>entertaining</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>76</td>\n","      <td>2</td>\n","      <td>independent</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>77</td>\n","      <td>2</td>\n","      <td>is worth seeking .</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>78</td>\n","      <td>2</td>\n","      <td>is worth seeking</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>79</td>\n","      <td>2</td>\n","      <td>is worth</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>80</td>\n","      <td>2</td>\n","      <td>worth</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>81</td>\n","      <td>2</td>\n","      <td>seeking</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    PhraseId    ...      Sentiment\n","63        64    ...              4\n","64        65    ...              3\n","65        66    ...              2\n","66        67    ...              4\n","67        68    ...              3\n","68        69    ...              2\n","69        70    ...              3\n","70        71    ...              3\n","71        72    ...              3\n","72        73    ...              2\n","73        74    ...              2\n","74        75    ...              4\n","75        76    ...              2\n","76        77    ...              3\n","77        78    ...              4\n","78        79    ...              2\n","79        80    ...              2\n","80        81    ...              2\n","\n","[18 rows x 4 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train.loc[train.SentenceId == 2]"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"4f75e24b86e3aeb7477fa1cd69789992233420b1","execution":{"iopub.execute_input":"2024-03-31T12:13:18.389850Z","iopub.status.busy":"2024-03-31T12:13:18.389617Z","iopub.status.idle":"2024-03-31T12:13:18.420706Z","shell.execute_reply":"2024-03-31T12:13:18.420120Z","shell.execute_reply.started":"2024-03-31T12:13:18.389804Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average count of phrases per sentence in train is 18.\n","Average count of phrases per sentence in test is 20.\n"]}],"source":["print('Average count of phrases per sentence in train is {0:.0f}.'.format(train.groupby('SentenceId')['Phrase'].count().mean()))\n","print('Average count of phrases per sentence in test is {0:.0f}.'.format(test.groupby('SentenceId')['Phrase'].count().mean()))"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"ca3148a6bbdd0f71e4909feb5dca874fa6d64a2e","execution":{"iopub.execute_input":"2024-03-31T12:13:18.422163Z","iopub.status.busy":"2024-03-31T12:13:18.421906Z","iopub.status.idle":"2024-03-31T12:13:18.428632Z","shell.execute_reply":"2024-03-31T12:13:18.427967Z","shell.execute_reply.started":"2024-03-31T12:13:18.422117Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of phrases in train: 156060. Number of sentences in train: 8529.\n","Number of phrases in test: 66292. Number of sentences in test: 3310.\n"]}],"source":["print('Number of phrases in train: {}. Number of sentences in train: {}.'.format(train.shape[0], len(train.SentenceId.unique())))\n","print('Number of phrases in test: {}. Number of sentences in test: {}.'.format(test.shape[0], len(test.SentenceId.unique())))"]},{"cell_type":"code","execution_count":11,"metadata":{"_uuid":"bef53d8f659b78e3fc6b1ed07025591d55b7c128","execution":{"iopub.execute_input":"2024-03-31T12:13:18.430425Z","iopub.status.busy":"2024-03-31T12:13:18.430060Z","iopub.status.idle":"2024-03-31T12:13:18.728595Z","shell.execute_reply":"2024-03-31T12:13:18.727842Z","shell.execute_reply.started":"2024-03-31T12:13:18.430250Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average word length of phrases in train is 7.\n","Average word length of phrases in test is 7.\n"]}],"source":["print('Average word length of phrases in train is {0:.0f}.'.format(np.mean(train['Phrase'].apply(lambda x: len(x.split())))))\n","print('Average word length of phrases in test is {0:.0f}.'.format(np.mean(test['Phrase'].apply(lambda x: len(x.split())))))"]},{"cell_type":"markdown","metadata":{"_uuid":"9ee27697b41dfdca9cdb482bfc85cfd3d63ae6e2"},"source":["We can see than sentences were split in 18-20 phrases at average and a lot of phrases contain each other. Sometimes one word or even one punctuation mark influences the sentiment"]},{"cell_type":"markdown","metadata":{"_uuid":"9d1efbed65f250d37472544f4fe37cb6fd13e183","trusted":true},"source":["Let's see for example most common trigrams for positive phrases"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"4a128ab1d36eef6ec47161705a2b1094b830fe10","execution":{"iopub.execute_input":"2024-03-31T12:13:18.730053Z","iopub.status.busy":"2024-03-31T12:13:18.729779Z","iopub.status.idle":"2024-03-31T12:13:18.802943Z","shell.execute_reply":"2024-03-31T12:13:18.802330Z","shell.execute_reply.started":"2024-03-31T12:13:18.729987Z"},"trusted":true},"outputs":[],"source":["text = ' '.join(train.loc[train.Sentiment == 4, 'Phrase'].values)\n","text_trigrams = [i for i in ngrams(text.split(), 3)]"]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"b5c8533c5861794d44b53dbb2e5ef764e5e88119","execution":{"iopub.execute_input":"2024-03-31T12:13:18.804247Z","iopub.status.busy":"2024-03-31T12:13:18.803994Z","iopub.status.idle":"2024-03-31T12:13:18.852112Z","shell.execute_reply":"2024-03-31T12:13:18.851514Z","shell.execute_reply.started":"2024-03-31T12:13:18.804201Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[(('one', 'of', 'the'), 199),\n"," (('of', 'the', 'year'), 103),\n"," (('.', 'is', 'a'), 87),\n"," (('of', 'the', 'best'), 80),\n"," (('of', 'the', 'most'), 70),\n"," (('is', 'one', 'of'), 50),\n"," (('One', 'of', 'the'), 43),\n"," ((',', 'and', 'the'), 40),\n"," (('the', 'year', \"'s\"), 38),\n"," (('It', \"'s\", 'a'), 38),\n"," (('it', \"'s\", 'a'), 37),\n"," (('.', \"'s\", 'a'), 37),\n"," (('a', 'movie', 'that'), 35),\n"," (('the', 'edge', 'of'), 34),\n"," (('the', 'kind', 'of'), 33),\n"," (('of', 'your', 'seat'), 33),\n"," (('the', 'film', 'is'), 31),\n"," ((',', 'this', 'is'), 31),\n"," (('the', 'film', \"'s\"), 31),\n"," ((',', 'the', 'film'), 30),\n"," (('film', 'that', 'is'), 30),\n"," (('as', 'one', 'of'), 30),\n"," (('edge', 'of', 'your'), 29),\n"," ((',', 'it', \"'s\"), 27),\n"," (('a', 'film', 'that'), 27),\n"," (('as', 'well', 'as'), 27),\n"," ((',', 'funny', ','), 25),\n"," ((',', 'but', 'it'), 23),\n"," (('films', 'of', 'the'), 23),\n"," (('some', 'of', 'the'), 23)]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["Counter(text_trigrams).most_common(30)"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"402c0b58fe43a680bea33e1813012bec5c16cb55","execution":{"iopub.execute_input":"2024-03-31T12:13:18.853652Z","iopub.status.busy":"2024-03-31T12:13:18.853424Z","iopub.status.idle":"2024-03-31T12:13:33.106055Z","shell.execute_reply":"2024-03-31T12:13:33.105354Z","shell.execute_reply.started":"2024-03-31T12:13:18.853608Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[((',', 'funny', ','), 33),\n"," (('one', 'year', \"'s\"), 28),\n"," (('year', \"'s\", 'best'), 26),\n"," (('movies', 'ever', 'made'), 19),\n"," ((',', 'solid', 'cast'), 19),\n"," (('solid', 'cast', ','), 18),\n"," ((\"'ve\", 'ever', 'seen'), 16),\n"," (('.', 'It', \"'s\"), 16),\n"," ((',', 'making', 'one'), 15),\n"," (('best', 'films', 'year'), 15),\n"," ((',', 'touching', ','), 15),\n"," (('exquisite', 'acting', ','), 15),\n"," (('acting', ',', 'inventive'), 14),\n"," ((',', 'inventive', 'screenplay'), 14),\n"," (('jaw-dropping', 'action', 'sequences'), 14),\n"," (('good', 'acting', ','), 14),\n"," ((\"'s\", 'best', 'films'), 14),\n"," (('I', \"'ve\", 'seen'), 14),\n"," (('funny', ',', 'even'), 14),\n"," (('best', 'war', 'movies'), 13),\n"," (('purely', 'enjoyable', 'satisfying'), 13),\n"," (('funny', ',', 'touching'), 13),\n"," ((',', 'smart', ','), 13),\n"," (('inventive', 'screenplay', ','), 13),\n"," (('funniest', 'jokes', 'movie'), 13),\n"," (('action', 'sequences', ','), 13),\n"," (('sequences', ',', 'striking'), 13),\n"," ((',', 'striking', 'villains'), 13),\n"," (('exquisite', 'motion', 'picture'), 13),\n"," (('war', 'movies', 'ever'), 12)]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["text = ' '.join(train.loc[train.Sentiment == 4, 'Phrase'].values)\n","text = [i for i in text.split() if i not in stopwords.words('english')]\n","text_trigrams = [i for i in ngrams(text, 3)]\n","Counter(text_trigrams).most_common(30)"]},{"cell_type":"markdown","metadata":{"_uuid":"f59db6ed32fafb024728fd95b96157f278682a74"},"source":["The results show the main problem with this dataset: there are to many common words due to sentenced splitted in phrases. As a result stopwords shouldn't be removed from text."]},{"cell_type":"markdown","metadata":{"_uuid":"10dc8fc8d535ef492a3dab1b85b4052feec756ee"},"source":["### Thoughts on feature processing and engineering"]},{"cell_type":"markdown","metadata":{"_uuid":"d5d018a694d10cbd9e8e89c26d5227fdb9cf8c0b"},"source":["So, we have only phrases as data. And a phrase can contain a single word. And one punctuation mark can cause phrase to receive a different sentiment. Also assigned sentiments can be strange. This means several things:\n","- using stopwords can be a bad idea, especially when phrases contain one single stopword;\n","- puntuation could be important, so it should be used;\n","- ngrams are necessary to get the most info from data;\n","- using features like word count or sentence length won't be useful;"]},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"bd603ad818970c3c8c6db5e430a6cb8ae8eafbd5","execution":{"iopub.execute_input":"2024-03-31T12:13:33.107457Z","iopub.status.busy":"2024-03-31T12:13:33.107202Z","iopub.status.idle":"2024-03-31T12:13:33.110733Z","shell.execute_reply":"2024-03-31T12:13:33.109959Z","shell.execute_reply.started":"2024-03-31T12:13:33.107408Z"},"trusted":true},"outputs":[],"source":["tokenizer = TweetTokenizer()"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"7ebc937fd5ec811bc5c529ff416180fe338d073d","execution":{"iopub.execute_input":"2024-03-31T12:13:33.112142Z","iopub.status.busy":"2024-03-31T12:13:33.111896Z","iopub.status.idle":"2024-03-31T12:14:03.243176Z","shell.execute_reply":"2024-03-31T12:14:03.242336Z","shell.execute_reply.started":"2024-03-31T12:13:33.112102Z"},"trusted":true},"outputs":[],"source":["vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n","full_text = list(train['Phrase'].values) + list(test['Phrase'].values)\n","vectorizer.fit(full_text)\n","train_vectorized = vectorizer.transform(train['Phrase'])\n","test_vectorized = vectorizer.transform(test['Phrase'])"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"3d0bb4539b1e0b5f8439878a967ce7b5ece23f60","execution":{"iopub.execute_input":"2024-03-31T12:14:03.245201Z","iopub.status.busy":"2024-03-31T12:14:03.244807Z","iopub.status.idle":"2024-03-31T12:14:03.250521Z","shell.execute_reply":"2024-03-31T12:14:03.248944Z","shell.execute_reply.started":"2024-03-31T12:14:03.245011Z"},"trusted":true},"outputs":[],"source":["y = train['Sentiment']"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"75a7acfd815fb391cad92eed8d2f13e5c9801de8","execution":{"iopub.execute_input":"2024-03-31T12:14:03.252200Z","iopub.status.busy":"2024-03-31T12:14:03.251862Z","iopub.status.idle":"2024-03-31T12:14:03.263388Z","shell.execute_reply":"2024-03-31T12:14:03.262361Z","shell.execute_reply.started":"2024-03-31T12:14:03.252146Z"},"trusted":true},"outputs":[],"source":["logreg = LogisticRegression()\n","ovr = OneVsRestClassifier(logreg)"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"5a0bf05b880e0d05da378b753394e5a631753e82","execution":{"iopub.execute_input":"2024-03-31T12:14:03.264782Z","iopub.status.busy":"2024-03-31T12:14:03.264489Z","iopub.status.idle":"2024-03-31T12:14:10.840440Z","shell.execute_reply":"2024-03-31T12:14:10.839749Z","shell.execute_reply.started":"2024-03-31T12:14:03.264723Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 7.54 s, sys: 25 ms, total: 7.56 s\n","Wall time: 7.56 s\n"]},{"data":{"text/plain":["OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='warn',\n","          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False),\n","          n_jobs=None)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","ovr.fit(train_vectorized, y)"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"5946485410c25ae5033bf39e29f49f606ea87bfe","execution":{"iopub.execute_input":"2024-03-31T12:14:10.842137Z","iopub.status.busy":"2024-03-31T12:14:10.841878Z","iopub.status.idle":"2024-03-31T12:14:24.468439Z","shell.execute_reply":"2024-03-31T12:14:24.467458Z","shell.execute_reply.started":"2024-03-31T12:14:10.842085Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross-validation mean accuracy 56.55%, std 0.07.\n"]}],"source":["scores = cross_val_score(ovr, train_vectorized, y, scoring='accuracy', n_jobs=-1, cv=3)\n","print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"]},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"755c2b04f7bf8e86e9dc6242f392a575c61a052c","execution":{"iopub.execute_input":"2024-03-31T12:14:24.470695Z","iopub.status.busy":"2024-03-31T12:14:24.470371Z","iopub.status.idle":"2024-03-31T12:14:38.173095Z","shell.execute_reply":"2024-03-31T12:14:38.172240Z","shell.execute_reply.started":"2024-03-31T12:14:24.470633Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross-validation mean accuracy 56.51%, std 0.68.\n","CPU times: user 67.4 ms, sys: 13.2 ms, total: 80.7 ms\n","Wall time: 13.7 s\n"]}],"source":["%%time\n","svc = LinearSVC(dual=False)\n","scores = cross_val_score(svc, train_vectorized, y, scoring='accuracy', n_jobs=-1, cv=3)\n","print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"55a5845de3412244cfa9f0a11392e50c76d78184","execution":{"iopub.execute_input":"2024-03-31T12:14:38.174702Z","iopub.status.busy":"2024-03-31T12:14:38.174488Z","iopub.status.idle":"2024-03-31T12:15:00.691845Z","shell.execute_reply":"2024-03-31T12:15:00.691222Z","shell.execute_reply.started":"2024-03-31T12:14:38.174664Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"]}],"source":["ovr.fit(train_vectorized, y);\n","svc.fit(train_vectorized, y);"]},{"cell_type":"markdown","metadata":{"_uuid":"398461363c7a395e2a982e07e8ac6fccaee139c1"},"source":["## Deep learning\n","And now let's try DL. DL should work better for text classification with multiple layers. I use an architecture similar to those which were used in toxic competition."]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"eb29ec027df57f6597dbef976645dc8d151e1618","execution":{"iopub.execute_input":"2024-03-31T12:15:00.693627Z","iopub.status.busy":"2024-03-31T12:15:00.693306Z","iopub.status.idle":"2024-03-31T12:15:00.777979Z","shell.execute_reply":"2024-03-31T12:15:00.777340Z","shell.execute_reply.started":"2024-03-31T12:15:00.693568Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]}],"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n","from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n","from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n","from keras.models import Model, load_model\n","from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n","from keras import backend as K\n","from keras.engine import InputSpec, Layer\n","from keras.optimizers import Adam\n","\n","from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping"]},{"cell_type":"code","execution_count":24,"metadata":{"_uuid":"a2881c29f82578b4a373b52d2c7b96a2e73bfd80","execution":{"iopub.execute_input":"2024-03-31T12:15:00.779605Z","iopub.status.busy":"2024-03-31T12:15:00.779389Z","iopub.status.idle":"2024-03-31T12:15:03.328334Z","shell.execute_reply":"2024-03-31T12:15:03.327568Z","shell.execute_reply.started":"2024-03-31T12:15:00.779567Z"},"trusted":true},"outputs":[],"source":["tk = Tokenizer(lower = True, filters='')\n","tk.fit_on_texts(full_text)"]},{"cell_type":"code","execution_count":25,"metadata":{"_uuid":"1724669c7ca010d1bbf75e200211afdead768d1f","execution":{"iopub.execute_input":"2024-03-31T12:15:03.329673Z","iopub.status.busy":"2024-03-31T12:15:03.329454Z","iopub.status.idle":"2024-03-31T12:15:05.841348Z","shell.execute_reply":"2024-03-31T12:15:05.840697Z","shell.execute_reply.started":"2024-03-31T12:15:03.329634Z"},"trusted":true},"outputs":[],"source":["train_tokenized = tk.texts_to_sequences(train['Phrase'])\n","test_tokenized = tk.texts_to_sequences(test['Phrase'])"]},{"cell_type":"code","execution_count":26,"metadata":{"_uuid":"bcb80cf8a59ca779a0be1ab235a1e9da2f4b175b","execution":{"iopub.execute_input":"2024-03-31T12:15:05.842997Z","iopub.status.busy":"2024-03-31T12:15:05.842771Z","iopub.status.idle":"2024-03-31T12:15:07.450454Z","shell.execute_reply":"2024-03-31T12:15:07.449789Z","shell.execute_reply.started":"2024-03-31T12:15:05.842960Z"},"trusted":true},"outputs":[],"source":["max_len = 50\n","X_train = pad_sequences(train_tokenized, maxlen = max_len)\n","X_test = pad_sequences(test_tokenized, maxlen = max_len)"]},{"cell_type":"code","execution_count":27,"metadata":{"_uuid":"9dfd0b8fa2c79bfa206d2fe8e35fbec444418f5c","execution":{"iopub.execute_input":"2024-03-31T12:15:07.452047Z","iopub.status.busy":"2024-03-31T12:15:07.451768Z","iopub.status.idle":"2024-03-31T12:15:07.455364Z","shell.execute_reply":"2024-03-31T12:15:07.454564Z","shell.execute_reply.started":"2024-03-31T12:15:07.451983Z"},"trusted":true},"outputs":[],"source":["embedding_path = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\""]},{"cell_type":"code","execution_count":28,"metadata":{"_uuid":"d74c2aa2f13e8544f045e5644d5bac70e248a8bd","execution":{"iopub.execute_input":"2024-03-31T12:15:07.456777Z","iopub.status.busy":"2024-03-31T12:15:07.456551Z","iopub.status.idle":"2024-03-31T12:15:07.468908Z","shell.execute_reply":"2024-03-31T12:15:07.468227Z","shell.execute_reply.started":"2024-03-31T12:15:07.456731Z"},"trusted":true},"outputs":[],"source":["embed_size = 300\n","max_features = 30000"]},{"cell_type":"code","execution_count":29,"metadata":{"_uuid":"cdb522c23b75331481145b789cf127b39d47eaa1","execution":{"iopub.execute_input":"2024-03-31T12:15:07.470256Z","iopub.status.busy":"2024-03-31T12:15:07.470054Z","iopub.status.idle":"2024-03-31T12:18:57.169692Z","shell.execute_reply":"2024-03-31T12:18:57.169009Z","shell.execute_reply.started":"2024-03-31T12:15:07.470214Z"},"trusted":true},"outputs":[],"source":["def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n","\n","word_index = tk.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix = np.zeros((nb_words + 1, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embedding_index.get(word)\n","    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":30,"metadata":{"_uuid":"365c0d607d55a78c5890268b9c168eb12a211855","execution":{"iopub.execute_input":"2024-03-31T12:18:57.171266Z","iopub.status.busy":"2024-03-31T12:18:57.171047Z","iopub.status.idle":"2024-03-31T12:18:57.205782Z","shell.execute_reply":"2024-03-31T12:18:57.205145Z","shell.execute_reply.started":"2024-03-31T12:18:57.171229Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n"]}],"source":["from sklearn.preprocessing import OneHotEncoder\n","ohe = OneHotEncoder(sparse=False)\n","y_ohe = ohe.fit_transform(y.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":31,"metadata":{"_uuid":"594273c2d887315d083a35a5ffd7c2dd40c2ebb6","execution":{"iopub.execute_input":"2024-03-31T12:18:57.207458Z","iopub.status.busy":"2024-03-31T12:18:57.207159Z","iopub.status.idle":"2024-03-31T12:18:57.220256Z","shell.execute_reply":"2024-03-31T12:18:57.219640Z","shell.execute_reply.started":"2024-03-31T12:18:57.207403Z"},"trusted":true},"outputs":[],"source":["def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n","    file_path = \"best_model.hdf5\"\n","    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n","                                  save_best_only = True, mode = \"min\")\n","    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n","    \n","    inp = Input(shape = (max_len,))\n","    x = Embedding(19479, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n","    x1 = SpatialDropout1D(spatial_dr)(x)\n","\n","    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n","    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n","    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n","    max_pool1_gru = GlobalMaxPooling1D()(x1)\n","    \n","    x3 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n","    avg_pool3_gru = GlobalAveragePooling1D()(x3)\n","    max_pool3_gru = GlobalMaxPooling1D()(x3)\n","    \n","    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n","    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n","    avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n","    max_pool1_lstm = GlobalMaxPooling1D()(x1)\n","    \n","    x3 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n","    avg_pool3_lstm = GlobalAveragePooling1D()(x3)\n","    max_pool3_lstm = GlobalMaxPooling1D()(x3)\n","    \n","    \n","    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru,\n","                    avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n","    x = BatchNormalization()(x)\n","    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n","    x = BatchNormalization()(x)\n","    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n","    x = Dense(5, activation = \"sigmoid\")(x)\n","    model = Model(inputs = inp, outputs = x)\n","    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n","    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 20, validation_split=0.1, \n","                        verbose = 1, callbacks = [check_point, early_stop])\n","    model = load_model(file_path)\n","    return model"]},{"cell_type":"markdown","metadata":{"_uuid":"95f52b1f6de4e939c8d21e3525503912282fbd47"},"source":["An attempt at ensemble:"]},{"cell_type":"code","execution_count":32,"metadata":{"_uuid":"5eb586c98fb75c25cac099cd03d8233185fdc317","execution":{"iopub.execute_input":"2024-03-31T12:18:57.221874Z","iopub.status.busy":"2024-03-31T12:18:57.221642Z","iopub.status.idle":"2024-03-31T12:23:08.175588Z","shell.execute_reply":"2024-03-31T12:23:08.174637Z","shell.execute_reply.started":"2024-03-31T12:18:57.221828Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 140454 samples, validate on 15606 samples\n","Epoch 1/20\n","140454/140454 [==============================] - 29s 208us/step - loss: 0.3547 - acc: 0.8396 - val_loss: 0.3151 - val_acc: 0.8534\n","\n","Epoch 00001: val_loss improved from inf to 0.31512, saving model to best_model.hdf5\n","Epoch 2/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.3109 - acc: 0.8586 - val_loss: 0.3163 - val_acc: 0.8533\n","\n","Epoch 00002: val_loss did not improve from 0.31512\n","Epoch 3/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2997 - acc: 0.8627 - val_loss: 0.3141 - val_acc: 0.8537\n","\n","Epoch 00003: val_loss improved from 0.31512 to 0.31410, saving model to best_model.hdf5\n","Epoch 4/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2913 - acc: 0.8667 - val_loss: 0.3085 - val_acc: 0.8559\n","\n","Epoch 00004: val_loss improved from 0.31410 to 0.30845, saving model to best_model.hdf5\n","Epoch 5/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2848 - acc: 0.8699 - val_loss: 0.3051 - val_acc: 0.8555\n","\n","Epoch 00005: val_loss improved from 0.30845 to 0.30507, saving model to best_model.hdf5\n","Epoch 6/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2788 - acc: 0.8727 - val_loss: 0.3026 - val_acc: 0.8594\n","\n","Epoch 00006: val_loss improved from 0.30507 to 0.30256, saving model to best_model.hdf5\n","Epoch 7/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2749 - acc: 0.8744 - val_loss: 0.3002 - val_acc: 0.8600\n","\n","Epoch 00007: val_loss improved from 0.30256 to 0.30023, saving model to best_model.hdf5\n","Epoch 8/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2708 - acc: 0.8765 - val_loss: 0.3044 - val_acc: 0.8580\n","\n","Epoch 00008: val_loss did not improve from 0.30023\n","Epoch 9/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2676 - acc: 0.8782 - val_loss: 0.3064 - val_acc: 0.8585\n","\n","Epoch 00009: val_loss did not improve from 0.30023\n","Epoch 10/20\n","140454/140454 [==============================] - 22s 159us/step - loss: 0.2645 - acc: 0.8806 - val_loss: 0.3073 - val_acc: 0.8615\n","\n","Epoch 00010: val_loss did not improve from 0.30023\n"]}],"source":["model1 = build_model1(lr = 1e-3, lr_d = 1e-10, units = 64, spatial_dr = 0.3, kernel_size1=3, kernel_size2=2, dense_units=32, dr=0.1, conv_size=32)"]},{"cell_type":"code","execution_count":33,"metadata":{"_uuid":"b059392aad7d904adfb8ae151ad2004aa03da30d","execution":{"iopub.execute_input":"2024-03-31T12:23:08.177316Z","iopub.status.busy":"2024-03-31T12:23:08.177041Z","iopub.status.idle":"2024-03-31T12:27:04.732426Z","shell.execute_reply":"2024-03-31T12:27:04.731731Z","shell.execute_reply.started":"2024-03-31T12:23:08.177258Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 140454 samples, validate on 15606 samples\n","Epoch 1/20\n","140454/140454 [==============================] - 31s 221us/step - loss: 0.3572 - acc: 0.8381 - val_loss: 0.3236 - val_acc: 0.8467\n","\n","Epoch 00001: val_loss improved from inf to 0.32355, saving model to best_model.hdf5\n","Epoch 2/20\n","140454/140454 [==============================] - 27s 195us/step - loss: 0.3205 - acc: 0.8549 - val_loss: 0.3183 - val_acc: 0.8511\n","\n","Epoch 00002: val_loss improved from 0.32355 to 0.31827, saving model to best_model.hdf5\n","Epoch 3/20\n","140454/140454 [==============================] - 27s 195us/step - loss: 0.3112 - acc: 0.8584 - val_loss: 0.3067 - val_acc: 0.8562\n","\n","Epoch 00003: val_loss improved from 0.31827 to 0.30671, saving model to best_model.hdf5\n","Epoch 4/20\n","140454/140454 [==============================] - 27s 195us/step - loss: 0.3033 - acc: 0.8617 - val_loss: 0.3101 - val_acc: 0.8581\n","\n","Epoch 00004: val_loss did not improve from 0.30671\n","Epoch 5/20\n","140454/140454 [==============================] - 27s 195us/step - loss: 0.2972 - acc: 0.8640 - val_loss: 0.3001 - val_acc: 0.8602\n","\n","Epoch 00005: val_loss improved from 0.30671 to 0.30012, saving model to best_model.hdf5\n","Epoch 6/20\n","140454/140454 [==============================] - 27s 195us/step - loss: 0.2921 - acc: 0.8662 - val_loss: 0.3007 - val_acc: 0.8599\n","\n","Epoch 00006: val_loss did not improve from 0.30012\n","Epoch 7/20\n","140454/140454 [==============================] - 27s 195us/step - loss: 0.2870 - acc: 0.8686 - val_loss: 0.3026 - val_acc: 0.8592\n","\n","Epoch 00007: val_loss did not improve from 0.30012\n","Epoch 8/20\n","140454/140454 [==============================] - 27s 195us/step - loss: 0.2823 - acc: 0.8714 - val_loss: 0.3002 - val_acc: 0.8604\n","\n","Epoch 00008: val_loss did not improve from 0.30012\n"]}],"source":["model2 = build_model1(lr = 1e-3, lr_d = 1e-10, units = 128, spatial_dr = 0.5, kernel_size1=3, kernel_size2=2, dense_units=64, dr=0.2, conv_size=32)"]},{"cell_type":"code","execution_count":34,"metadata":{"_uuid":"8187e167ce93f0eb69f59cb9d7fedc4637a77cfe","execution":{"iopub.execute_input":"2024-03-31T12:27:04.734387Z","iopub.status.busy":"2024-03-31T12:27:04.734066Z","iopub.status.idle":"2024-03-31T12:27:04.747814Z","shell.execute_reply":"2024-03-31T12:27:04.746913Z","shell.execute_reply.started":"2024-03-31T12:27:04.734327Z"},"trusted":true},"outputs":[],"source":["def build_model2(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n","    file_path = \"best_model.hdf5\"\n","    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n","                                  save_best_only = True, mode = \"min\")\n","    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n","\n","    inp = Input(shape = (max_len,))\n","    x = Embedding(19479, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n","    x1 = SpatialDropout1D(spatial_dr)(x)\n","\n","    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n","    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n","    \n","    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n","    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1)\n","    max_pool1_gru = GlobalMaxPooling1D()(x_conv1)\n","    \n","    x_conv2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n","    avg_pool2_gru = GlobalAveragePooling1D()(x_conv2)\n","    max_pool2_gru = GlobalMaxPooling1D()(x_conv2)\n","    \n","    \n","    x_conv3 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n","    avg_pool1_lstm = GlobalAveragePooling1D()(x_conv3)\n","    max_pool1_lstm = GlobalMaxPooling1D()(x_conv3)\n","    \n","    x_conv4 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n","    avg_pool2_lstm = GlobalAveragePooling1D()(x_conv4)\n","    max_pool2_lstm = GlobalMaxPooling1D()(x_conv4)\n","    \n","    \n","    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool2_gru, max_pool2_gru,\n","                    avg_pool1_lstm, max_pool1_lstm, avg_pool2_lstm, max_pool2_lstm])\n","    x = BatchNormalization()(x)\n","    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n","    x = BatchNormalization()(x)\n","    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n","    x = Dense(5, activation = \"sigmoid\")(x)\n","    model = Model(inputs = inp, outputs = x)\n","    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n","    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 20, validation_split=0.1, \n","                        verbose = 1, callbacks = [check_point, early_stop])\n","    model = load_model(file_path)\n","    return model"]},{"cell_type":"code","execution_count":35,"metadata":{"_uuid":"9bf90d6d4effebb3c5aa9b666b8e09c9c57d94d3","execution":{"iopub.execute_input":"2024-03-31T12:27:04.749106Z","iopub.status.busy":"2024-03-31T12:27:04.748862Z","iopub.status.idle":"2024-03-31T12:35:41.121241Z","shell.execute_reply":"2024-03-31T12:35:41.120524Z","shell.execute_reply.started":"2024-03-31T12:27:04.749057Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 140454 samples, validate on 15606 samples\n","Epoch 1/20\n","140454/140454 [==============================] - 29s 205us/step - loss: 0.5599 - acc: 0.7178 - val_loss: 0.4037 - val_acc: 0.8339\n","\n","Epoch 00001: val_loss improved from inf to 0.40366, saving model to best_model.hdf5\n","Epoch 2/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3921 - acc: 0.8270 - val_loss: 0.3461 - val_acc: 0.8454\n","\n","Epoch 00002: val_loss improved from 0.40366 to 0.34614, saving model to best_model.hdf5\n","Epoch 3/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3644 - acc: 0.8369 - val_loss: 0.3327 - val_acc: 0.8462\n","\n","Epoch 00003: val_loss improved from 0.34614 to 0.33270, saving model to best_model.hdf5\n","Epoch 4/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3504 - acc: 0.8421 - val_loss: 0.3257 - val_acc: 0.8478\n","\n","Epoch 00004: val_loss improved from 0.33270 to 0.32570, saving model to best_model.hdf5\n","Epoch 5/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3413 - acc: 0.8461 - val_loss: 0.3215 - val_acc: 0.8497\n","\n","Epoch 00005: val_loss improved from 0.32570 to 0.32150, saving model to best_model.hdf5\n","Epoch 6/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3352 - acc: 0.8485 - val_loss: 0.3205 - val_acc: 0.8504\n","\n","Epoch 00006: val_loss improved from 0.32150 to 0.32047, saving model to best_model.hdf5\n","Epoch 7/20\n","140454/140454 [==============================] - 25s 176us/step - loss: 0.3297 - acc: 0.8510 - val_loss: 0.3202 - val_acc: 0.8516\n","\n","Epoch 00007: val_loss improved from 0.32047 to 0.32020, saving model to best_model.hdf5\n","Epoch 8/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3254 - acc: 0.8525 - val_loss: 0.3149 - val_acc: 0.8524\n","\n","Epoch 00008: val_loss improved from 0.32020 to 0.31495, saving model to best_model.hdf5\n","Epoch 9/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3219 - acc: 0.8536 - val_loss: 0.3137 - val_acc: 0.8527\n","\n","Epoch 00009: val_loss improved from 0.31495 to 0.31366, saving model to best_model.hdf5\n","Epoch 10/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3190 - acc: 0.8556 - val_loss: 0.3117 - val_acc: 0.8540\n","\n","Epoch 00010: val_loss improved from 0.31366 to 0.31174, saving model to best_model.hdf5\n","Epoch 11/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3162 - acc: 0.8560 - val_loss: 0.3117 - val_acc: 0.8552\n","\n","Epoch 00011: val_loss improved from 0.31174 to 0.31170, saving model to best_model.hdf5\n","Epoch 12/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3138 - acc: 0.8570 - val_loss: 0.3112 - val_acc: 0.8542\n","\n","Epoch 00012: val_loss improved from 0.31170 to 0.31123, saving model to best_model.hdf5\n","Epoch 13/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3120 - acc: 0.8582 - val_loss: 0.3093 - val_acc: 0.8552\n","\n","Epoch 00013: val_loss improved from 0.31123 to 0.30926, saving model to best_model.hdf5\n","Epoch 14/20\n","140454/140454 [==============================] - 25s 176us/step - loss: 0.3103 - acc: 0.8581 - val_loss: 0.3077 - val_acc: 0.8565\n","\n","Epoch 00014: val_loss improved from 0.30926 to 0.30768, saving model to best_model.hdf5\n","Epoch 15/20\n","140454/140454 [==============================] - 25s 176us/step - loss: 0.3084 - acc: 0.8594 - val_loss: 0.3083 - val_acc: 0.8562\n","\n","Epoch 00015: val_loss did not improve from 0.30768\n","Epoch 16/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3067 - acc: 0.8600 - val_loss: 0.3068 - val_acc: 0.8567\n","\n","Epoch 00016: val_loss improved from 0.30768 to 0.30683, saving model to best_model.hdf5\n","Epoch 17/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3053 - acc: 0.8603 - val_loss: 0.3075 - val_acc: 0.8567\n","\n","Epoch 00017: val_loss did not improve from 0.30683\n","Epoch 18/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3036 - acc: 0.8612 - val_loss: 0.3068 - val_acc: 0.8562\n","\n","Epoch 00018: val_loss did not improve from 0.30683\n","Epoch 19/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3024 - acc: 0.8620 - val_loss: 0.3057 - val_acc: 0.8576\n","\n","Epoch 00019: val_loss improved from 0.30683 to 0.30569, saving model to best_model.hdf5\n","Epoch 20/20\n","140454/140454 [==============================] - 25s 175us/step - loss: 0.3007 - acc: 0.8625 - val_loss: 0.3061 - val_acc: 0.8572\n","\n","Epoch 00020: val_loss did not improve from 0.30569\n"]}],"source":["model3 = build_model2(lr = 1e-4, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=4, kernel_size2=3, dense_units=32, dr=0.1, conv_size=32)"]},{"cell_type":"code","execution_count":36,"metadata":{"_uuid":"bf6d8d367c5adc30e00bbd77c1de70fd52960441","execution":{"iopub.execute_input":"2024-03-31T12:35:41.122928Z","iopub.status.busy":"2024-03-31T12:35:41.122665Z","iopub.status.idle":"2024-03-31T12:41:48.398570Z","shell.execute_reply":"2024-03-31T12:41:48.397721Z","shell.execute_reply.started":"2024-03-31T12:35:41.122877Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 140454 samples, validate on 15606 samples\n","Epoch 1/20\n","140454/140454 [==============================] - 29s 208us/step - loss: 0.3664 - acc: 0.8363 - val_loss: 0.3216 - val_acc: 0.8498\n","\n","Epoch 00001: val_loss improved from inf to 0.32160, saving model to best_model.hdf5\n","Epoch 2/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.3251 - acc: 0.8534 - val_loss: 0.3183 - val_acc: 0.8520\n","\n","Epoch 00002: val_loss improved from 0.32160 to 0.31827, saving model to best_model.hdf5\n","Epoch 3/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.3148 - acc: 0.8563 - val_loss: 0.3079 - val_acc: 0.8568\n","\n","Epoch 00003: val_loss improved from 0.31827 to 0.30794, saving model to best_model.hdf5\n","Epoch 4/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.3073 - acc: 0.8593 - val_loss: 0.3055 - val_acc: 0.8585\n","\n","Epoch 00004: val_loss improved from 0.30794 to 0.30549, saving model to best_model.hdf5\n","Epoch 5/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.3018 - acc: 0.8618 - val_loss: 0.3033 - val_acc: 0.8591\n","\n","Epoch 00005: val_loss improved from 0.30549 to 0.30330, saving model to best_model.hdf5\n","Epoch 6/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.2965 - acc: 0.8644 - val_loss: 0.3026 - val_acc: 0.8595\n","\n","Epoch 00006: val_loss improved from 0.30330 to 0.30257, saving model to best_model.hdf5\n","Epoch 7/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.2924 - acc: 0.8661 - val_loss: 0.3049 - val_acc: 0.8605\n","\n","Epoch 00007: val_loss did not improve from 0.30257\n","Epoch 8/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.2874 - acc: 0.8687 - val_loss: 0.3008 - val_acc: 0.8611\n","\n","Epoch 00008: val_loss improved from 0.30257 to 0.30079, saving model to best_model.hdf5\n","Epoch 9/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.2852 - acc: 0.8695 - val_loss: 0.3018 - val_acc: 0.8588\n","\n","Epoch 00009: val_loss did not improve from 0.30079\n","Epoch 10/20\n","140454/140454 [==============================] - 24s 171us/step - loss: 0.2820 - acc: 0.8711 - val_loss: 0.3015 - val_acc: 0.8609\n","\n","Epoch 00010: val_loss did not improve from 0.30079\n","Epoch 11/20\n","140454/140454 [==============================] - 24s 172us/step - loss: 0.2804 - acc: 0.8722 - val_loss: 0.2997 - val_acc: 0.8621\n","\n","Epoch 00011: val_loss improved from 0.30079 to 0.29969, saving model to best_model.hdf5\n","Epoch 12/20\n","140454/140454 [==============================] - 25s 176us/step - loss: 0.2776 - acc: 0.8732 - val_loss: 0.3016 - val_acc: 0.8605\n","\n","Epoch 00012: val_loss did not improve from 0.29969\n","Epoch 13/20\n","140454/140454 [==============================] - 25s 176us/step - loss: 0.2758 - acc: 0.8743 - val_loss: 0.3018 - val_acc: 0.8610\n","\n","Epoch 00013: val_loss did not improve from 0.29969\n","Epoch 14/20\n","140454/140454 [==============================] - 24s 174us/step - loss: 0.2738 - acc: 0.8757 - val_loss: 0.3038 - val_acc: 0.8610\n","\n","Epoch 00014: val_loss did not improve from 0.29969\n"]}],"source":["model4 = build_model2(lr = 1e-3, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.3, conv_size=32)"]},{"cell_type":"code","execution_count":37,"metadata":{"_uuid":"b10113439be683bf19930750eaf96328e5b58d42","execution":{"iopub.execute_input":"2024-03-31T12:41:48.400100Z","iopub.status.busy":"2024-03-31T12:41:48.399837Z","iopub.status.idle":"2024-03-31T12:45:26.392271Z","shell.execute_reply":"2024-03-31T12:45:26.391589Z","shell.execute_reply.started":"2024-03-31T12:41:48.400043Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 140454 samples, validate on 15606 samples\n","Epoch 1/20\n","140454/140454 [==============================] - 33s 232us/step - loss: 0.3988 - acc: 0.8141 - val_loss: 0.3200 - val_acc: 0.8514\n","\n","Epoch 00001: val_loss improved from inf to 0.31997, saving model to best_model.hdf5\n","Epoch 2/20\n","140454/140454 [==============================] - 26s 185us/step - loss: 0.3211 - acc: 0.8549 - val_loss: 0.3134 - val_acc: 0.8540\n","\n","Epoch 00002: val_loss improved from 0.31997 to 0.31341, saving model to best_model.hdf5\n","Epoch 3/20\n","140454/140454 [==============================] - 26s 185us/step - loss: 0.3075 - acc: 0.8598 - val_loss: 0.3067 - val_acc: 0.8580\n","\n","Epoch 00003: val_loss improved from 0.31341 to 0.30669, saving model to best_model.hdf5\n","Epoch 4/20\n","140454/140454 [==============================] - 26s 186us/step - loss: 0.2985 - acc: 0.8630 - val_loss: 0.3027 - val_acc: 0.8608\n","\n","Epoch 00004: val_loss improved from 0.30669 to 0.30274, saving model to best_model.hdf5\n","Epoch 5/20\n","140454/140454 [==============================] - 26s 186us/step - loss: 0.2899 - acc: 0.8667 - val_loss: 0.3034 - val_acc: 0.8591\n","\n","Epoch 00005: val_loss did not improve from 0.30274\n","Epoch 6/20\n","140454/140454 [==============================] - 26s 184us/step - loss: 0.2849 - acc: 0.8694 - val_loss: 0.3054 - val_acc: 0.8596\n","\n","Epoch 00006: val_loss did not improve from 0.30274\n","Epoch 7/20\n","140454/140454 [==============================] - 26s 185us/step - loss: 0.2793 - acc: 0.8722 - val_loss: 0.3085 - val_acc: 0.8590\n","\n","Epoch 00007: val_loss did not improve from 0.30274\n"]}],"source":["model5 = build_model2(lr = 1e-3, lr_d = 1e-7, units = 64, spatial_dr = 0.3, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.4, conv_size=64)"]},{"cell_type":"code","execution_count":38,"metadata":{"_uuid":"8529014d1a239f308ac5f2552088ce2d8ebb8966","execution":{"iopub.execute_input":"2024-03-31T12:45:26.393857Z","iopub.status.busy":"2024-03-31T12:45:26.393629Z","iopub.status.idle":"2024-03-31T12:45:43.146827Z","shell.execute_reply":"2024-03-31T12:45:43.146154Z","shell.execute_reply.started":"2024-03-31T12:45:26.393819Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["66292/66292 [==============================] - 3s 48us/step\n","66292/66292 [==============================] - 4s 59us/step\n","66292/66292 [==============================] - 3s 48us/step\n","66292/66292 [==============================] - 3s 48us/step\n","66292/66292 [==============================] - 3s 50us/step\n"]}],"source":["pred1 = model1.predict(X_test, batch_size = 1024, verbose = 1)\n","pred = pred1\n","pred2 = model2.predict(X_test, batch_size = 1024, verbose = 1)\n","pred += pred2\n","pred3 = model3.predict(X_test, batch_size = 1024, verbose = 1)\n","pred += pred3\n","pred4 = model4.predict(X_test, batch_size = 1024, verbose = 1)\n","pred += pred4\n","pred5 = model5.predict(X_test, batch_size = 1024, verbose = 1)\n","pred += pred5"]},{"cell_type":"code","execution_count":39,"metadata":{"_uuid":"d58a5b52ea647dab51123ef89878c5355b3d2971","execution":{"iopub.execute_input":"2024-03-31T12:45:43.148527Z","iopub.status.busy":"2024-03-31T12:45:43.148274Z","iopub.status.idle":"2024-03-31T12:45:43.638037Z","shell.execute_reply":"2024-03-31T12:45:43.637392Z","shell.execute_reply.started":"2024-03-31T12:45:43.148477Z"},"trusted":true},"outputs":[],"source":["predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n","sub['Sentiment'] = predictions\n","sub.to_csv(\"blend.csv\", index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":32092,"sourceId":10025,"sourceType":"competition"},{"datasetId":2568,"sourceId":4304,"sourceType":"datasetVersion"},{"datasetId":14154,"sourceId":19053,"sourceType":"datasetVersion"}],"dockerImageVersionId":18199,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
